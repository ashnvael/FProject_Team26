{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashnvael/FProject_Team26/blob/main/OTC_combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_R-OyXtIgfZH",
      "metadata": {
        "id": "_R-OyXtIgfZH"
      },
      "source": [
        "## Sobolev Training for NN solver for both PDE in General Equilibrium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NbKxrQJ0SAbF",
      "metadata": {
        "id": "NbKxrQJ0SAbF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(mountpoint = \"/content/drive\", force_remount = True)\n",
        "os.chdir(\"drive/MyDrive/OTC_risk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1198ac-7b4a-4123-aa9d-e6e72d352d95",
      "metadata": {
        "id": "ac1198ac-7b4a-4123-aa9d-e6e72d352d95"
      },
      "source": [
        "#### code on local machine starts here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fba8fd-6635-4030-a611-c63f4f951896",
      "metadata": {
        "id": "19fba8fd-6635-4030-a611-c63f4f951896"
      },
      "outputs": [],
      "source": [
        "# Define model name\n",
        "import os\n",
        "model_name = \"OTC_combined\"\n",
        "\n",
        "# Define model paths\n",
        "model_load_path = f\"./output/{model_name}/pretrained_model.pt\"\n",
        "model_V_save_path = f\"./output/{model_name}/trained_model_V.pt\"\n",
        "model_y_save_path = f\"./output/{model_name}/trained_model_y.pt\"\n",
        "\n",
        "loading_saved_model = False\n",
        "\n",
        "# Define figure save path\n",
        "fig_path = f\"./fig/{model_name}/\"\n",
        "os.makedirs(os.path.dirname(model_V_save_path), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(model_y_save_path), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80526493-9b6b-4dfe-ae10-5784d3f4bb98",
      "metadata": {
        "id": "80526493-9b6b-4dfe-ae10-5784d3f4bb98"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "from util import alpha_fn\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Union, Optional\n",
        "\n",
        "import numpy as np\n",
        "from PDE_nn import initialize_grids, initial_guess\n",
        "from PDE_nn import solve_y_pde, get_agg # functions to get aggregates and y on grid space\n",
        "from config import CompetitiveSearch\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36471c5-c448-4b3f-84f1-f8da87ae59bf",
      "metadata": {
        "id": "a36471c5-c448-4b3f-84f1-f8da87ae59bf"
      },
      "outputs": [],
      "source": [
        "param = CompetitiveSearch()\n",
        "W_grid, S_grid, x_grid, s_grid = initialize_grids(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NxfuucFioLw7",
      "metadata": {
        "id": "NxfuucFioLw7"
      },
      "outputs": [],
      "source": [
        "param.sigma = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7X-sC_lSGYyZ",
      "metadata": {
        "id": "7X-sC_lSGYyZ"
      },
      "outputs": [],
      "source": [
        "class Phase:\n",
        "    def __init__(self, lr: float,\n",
        "                 epochs: int,\n",
        "                 sigma: float = param.sigma,\n",
        "                 mode: str = \"both\"):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.sigma = sigma\n",
        "        self.mode = mode\n",
        "\n",
        "PHASES_LIST = [\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"y\"),\n",
        "               Phase(lr = 1e-5, epochs = 100, sigma = param.sigma, mode = \"V\"),\n",
        "               ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1619b996-680b-47f7-b5ec-135a1a240e2b",
      "metadata": {
        "id": "1619b996-680b-47f7-b5ec-135a1a240e2b"
      },
      "outputs": [],
      "source": [
        "class y_net(nn.Module):\n",
        "    def __init__(self, param, nn_width=50, nn_num_layers=3):\n",
        "        super(y_net, self).__init__()\n",
        "\n",
        "        self.input_dim = 2\n",
        "        self.output_dim = 1\n",
        "        self.param = param\n",
        "\n",
        "        # Define input layer\n",
        "        self.input_layer = nn.Linear(self.input_dim, nn_width)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "        # Define hidden layers\n",
        "        self.hidden_layers = nn.ModuleList(\n",
        "            [nn.Linear(nn_width, nn_width) for _ in range(nn_num_layers)]\n",
        "        )\n",
        "\n",
        "        # Define output layer\n",
        "        self.output_layer = nn.Linear(nn_width, self.output_dim)\n",
        "\n",
        "    def compute_pertrubation_soln(self, input):\n",
        "        x, s = input[:, 0], input[:, 1]\n",
        "\n",
        "        r1 = -0.5 * (1 + 1 / self.param.psi) * self.param.sigma**2 * (\n",
        "            self.param.gamma1 * x * (s / x)**2 + self.param.gamma2 * (1 - x) * ((1 - s) / (1 - x))**2\n",
        "        )\n",
        "        pi1 = (self.param.nu_tilde * self.param.gamma1 * (s / x) +\n",
        "               (1 - self.param.nu_tilde) * self.param.gamma2 * (1 - s) / (1 - x)) * self.param.sigma**2\n",
        "        soln = 1 / self.param.q_star + r1 + pi1\n",
        "        return soln.view(-1, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        perturbation_soln = self.compute_pertrubation_soln(input)\n",
        "\n",
        "        # Forward pass with implicit residual connections\n",
        "        x = self.activation(self.input_layer(input))\n",
        "        for layer in self.hidden_layers:\n",
        "            x = x + self.activation(layer(x))\n",
        "\n",
        "        out = self.output_layer(x)\n",
        "\n",
        "        return out #+ perturbation_soln # Residual learning\n",
        "\n",
        "class V_net(nn.Module):\n",
        "    def __init__(self, param, nn_width=50, nn_num_layers=3):\n",
        "        super(V_net, self).__init__()\n",
        "\n",
        "        self.input_dim = 4\n",
        "        self.output_dim = 1\n",
        "        self.param = param\n",
        "\n",
        "        # Define input layer\n",
        "        self.input_layer = nn.Linear(self.input_dim, nn_width)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "        # Define hidden layers (without using nn.Sequential)\n",
        "        self.hidden_layers = nn.ModuleList(\n",
        "            [nn.Linear(nn_width, nn_width) for _ in range(nn_num_layers)]\n",
        "        )\n",
        "\n",
        "        # Define output layer\n",
        "        self.output_layer = nn.Linear(nn_width, self.output_dim)\n",
        "        self.epsilon = 0.05\n",
        "\n",
        "        # Scaling parameters\n",
        "        W_scale = 1 / self.param.W_min\n",
        "        S_scale = self.param.S_max - self.param.S_min\n",
        "        x_scale = self.param.x_max - self.param.x_min\n",
        "        s_scale = self.param.s_max - self.param.s_min\n",
        "        scale_tensor = torch.tensor([W_scale, S_scale, x_scale, s_scale])\n",
        "        self.register_buffer('scale_tensor', scale_tensor)\n",
        "\n",
        "        subtr_tensor = torch.tensor([1/self.param.W_max, self.param.S_min, self.param.x_min, self.param.s_min])\n",
        "        self.register_buffer('subtr_tensor', subtr_tensor)\n",
        "\n",
        "    def compute_pertrubation_soln(self, input):\n",
        "        W, S, x, s = input[:, 0], input[:, 1], input[:, 2], input[:, 3]\n",
        "        V0 = self.param.A * W ** (1 - self.param.gamma) / (1 - self.param.gamma)\n",
        "        r1 = -0.5 * (1 + 1 / self.param.psi) * self.param.sigma**2 * (\n",
        "            self.param.gamma1 * x * (s / x)**2 + self.param.gamma2 * (1 - x) * ((1 - s) / (1 - x))**2\n",
        "        )\n",
        "        pi1 = (self.param.nu_tilde * self.param.gamma1 * (s / x) +\n",
        "               (1 - self.param.nu_tilde) * self.param.gamma2 * (1 - s) / (1 - x)) * self.param.sigma**2\n",
        "\n",
        "        V1 = (self.param.A * W ** (1 - self.param.gamma) / self.param.rho_star) * (\n",
        "            r1 + pi1 * S / (self.param.rho_star * W) - 0.5 * self.param.gamma * self.param.sigma**2 * (S / (self.param.rho_star * W))**2\n",
        "        )\n",
        "        soln = V0 + self.epsilon * V1\n",
        "\n",
        "        return soln.view(-1, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input_transformed = input.clone()\n",
        "        input_transformed[:, 0] = torch.pow(input[:, 0], 1 - self.param.gamma)\n",
        "        input_transformed = (input_transformed - self.subtr_tensor) / self.scale_tensor\n",
        "\n",
        "        perturbation_soln = self.compute_pertrubation_soln(input)\n",
        "\n",
        "        # Forward pass with implicit residual connections\n",
        "        x = self.activation(self.input_layer(input_transformed))  # Initial transformation\n",
        "        for layer in self.hidden_layers:\n",
        "            x = x + self.activation(layer(x))  # Residual connection\n",
        "\n",
        "        out = self.output_layer(x)\n",
        "\n",
        "        return out #+ perturbation_soln  # Residual learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fda18ae-daea-4ffc-b7e6-441d6b1eecfa",
      "metadata": {
        "id": "6fda18ae-daea-4ffc-b7e6-441d6b1eecfa"
      },
      "outputs": [],
      "source": [
        "from aggregate_fast import *\n",
        "from itertools import chain\n",
        "\n",
        "class Train_NN:\n",
        "    def __init__(self, param, input_dim, device=DEVICE):\n",
        "        self.param = param\n",
        "        self.device = device\n",
        "        self.model_V = V_net(param, nn_width = 64, nn_num_layers = 5).to(self.device)\n",
        "        self.model_y = y_net(param = param, nn_width = 64, nn_num_layers = 5).to(self.device)\n",
        "        self.phases: list[Phase] = PHASES_LIST\n",
        "        self.pretrain_losses_V = []\n",
        "        self.pretrain_losses_y = []\n",
        "        self.train_losses = []\n",
        "        self.optimizer_y = optim.Adam(self.model_y.parameters(), lr=1e-4) ## ONLY FOR PRETRAINING\n",
        "        self.optimizer_V = optim.Adam(self.model_V.parameters(), lr=1e-4) ## ONLY FOR PRETRAINING\n",
        "        self.agg = Aggregates(V_model = self.model_V, y_model = self.model_y,\n",
        "                              param = self.param, device = self.device)\n",
        "\n",
        "        ## TODO: make it more explicit and general - pretraining should align with phase 0\n",
        "        self.param.sigma = self.phases[0].sigma\n",
        "\n",
        "        # Initialize grids and precomputed aggregates\n",
        "        W_grid, S_grid, x_grid, s_grid = initialize_grids(param)\n",
        "        self.x_grid, self.s_grid = x_grid, s_grid\n",
        "        _, self.V_init, self.y = initial_guess(W_grid, S_grid, x_grid, s_grid, param)\n",
        "        self.y = torch.tensor(self.y, device = DEVICE)\n",
        "\n",
        "\n",
        "    def update_training_mode(self, mode: str) -> None:\n",
        "\n",
        "        if mode == \"y\" or mode == \"train_y\":\n",
        "            self.model_V.eval()\n",
        "            self.model_y.train()\n",
        "            for param in self.model_V.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.model_y.parameters():\n",
        "                param.requires_grad = True\n",
        "        elif mode == \"V\" or mode == \"train_V\":\n",
        "            self.model_V.train()\n",
        "            self.model_y.eval()\n",
        "            for param in self.model_V.parameters():\n",
        "                param.requires_grad = True\n",
        "            for param in self.model_y.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        elif mode == \"both\" or mode is None:\n",
        "            self.model_V.eval()\n",
        "            self.model_y.eval()\n",
        "            for param in self.model_V.parameters():\n",
        "                param.requires_grad = True\n",
        "            for param in self.model_y.parameters():\n",
        "                param.requires_grad = True\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown training mode {mode} (expected 'V', 'y', 'both')\")\n",
        "\n",
        "\n",
        "    def compute_initial_guess_y(self, x, s):\n",
        "        \"\"\"\n",
        "        Compute the initial guess for \\( y(x, s) \\) using the given formula.\n",
        "        \"\"\"\n",
        "        # Parameters\n",
        "        q_star = self.param.q_star\n",
        "        sigma = self.param.sigma\n",
        "        psi = self.param.psi\n",
        "        gamma1 = self.param.gamma1\n",
        "        gamma2 = self.param.gamma2\n",
        "        nu_tilde = self.param.nu_tilde\n",
        "\n",
        "        # Compute r1 and pi1\n",
        "        r1 = -0.5 * (1 + 1 / psi) * sigma**2 * (\n",
        "            gamma1 * x * (s / x)**2 + gamma2 * (1 - x) * ((1 - s) / (1 - x))**2\n",
        "        )\n",
        "        pi1 = (nu_tilde * gamma1 * (s / x) + (1 - nu_tilde) * gamma2 * (1 - s) / (1 - x)) * sigma**2\n",
        "\n",
        "        # Compute the initial guess for y(x, s)\n",
        "        y_guess = 1 / q_star + r1 + pi1\n",
        "        return y_guess\n",
        "\n",
        "\n",
        "    def compute_initial_guess_V(self, W, S, x, s):\n",
        "        \"\"\"\n",
        "        Compute the initial guess for \\( V(W, S, x, s) \\) using the given formula.\n",
        "        \"\"\"\n",
        "        A = self.param.A\n",
        "        gamma = self.param.gamma\n",
        "        rho_star = self.param.rho_star\n",
        "        sigma = self.param.sigma\n",
        "        psi = self.param.psi\n",
        "        gamma1 = self.param.gamma1\n",
        "        gamma2 = self.param.gamma2\n",
        "        nu_tilde = self.param.nu_tilde\n",
        "        epsilon = 0.05  # Perturbation factor\n",
        "\n",
        "        # Components of \\( V \\)\n",
        "        V0 = A * W ** (1 - gamma) / (1 - gamma)\n",
        "        r1 = -0.5 * (1 + 1 / psi) * sigma**2 * (gamma1 * x * (s / x)**2 + gamma2 * (1 - x) * ((1 - s) / (1 - x))**2)\n",
        "        pi1 = (nu_tilde * gamma1 * (s / x) + (1 - nu_tilde) * gamma2 * (1 - s) / (1 - x)) * sigma**2\n",
        "\n",
        "        V1 = (A * W ** (1 - gamma) / rho_star) * (r1 + pi1 * S / (rho_star * W) -\n",
        "            0.5 * gamma * sigma**2 * (S / (rho_star * W))**2)\n",
        "\n",
        "        return V0 + epsilon * V1\n",
        "\n",
        "\n",
        "    def sample_data_y(self, num_samples, x_s_distance_min = 0.01):\n",
        "        \"\"\"\n",
        "        Sample data points for \\( W, S, x, s \\) ensuring that \\( |x - s| \\geq x_s_distance_min \\).\n",
        "        \"\"\"\n",
        "\n",
        "        # Sample x\n",
        "        x_mean = (self.param.x_min + self.param.x_max) / 2\n",
        "        x_std = (self.param.x_max - self.param.x_min) / 6\n",
        "        x = torch.normal(x_mean, x_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        x = torch.clamp(x, min=self.param.x_min, max=self.param.x_max)\n",
        "\n",
        "        # Sample s ensuring |x - s| >= x_s_distance_min\n",
        "        s_mean = (self.param.s_min + self.param.s_max) / 2\n",
        "        s_std = (self.param.s_max - self.param.s_min) / 6\n",
        "        s = torch.normal(s_mean, s_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        s = torch.clamp(s, min=self.param.s_min, max=self.param.s_max)\n",
        "\n",
        "        # Return the concatenated tensor\n",
        "        return torch.cat([x, s], dim=1)\n",
        "\n",
        "\n",
        "    def sample_data_V(self, num_samples, x_s_distance_min = 0.01):\n",
        "        \"\"\"\n",
        "        Sample data points for \\( W, S, x, s \\) ensuring that \\( |x - s| \\geq x_s_distance_min \\).\n",
        "        \"\"\"\n",
        "        # Sample W\n",
        "        W_mean = (self.param.W_min + self.param.W_max) / 2\n",
        "        W_std = (self.param.W_max - self.param.W_min) / 24\n",
        "        W = torch.normal(W_mean, W_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        W = torch.clamp(W, min=self.param.W_min, max=self.param.W_max)\n",
        "\n",
        "        # Sample S\n",
        "        S_mean = (self.param.S_min + self.param.S_max) / 2\n",
        "        S_std = (self.param.S_max - self.param.S_min) / 6\n",
        "        S = torch.normal(S_mean, S_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        S = torch.clamp(S, min=self.param.S_min, max=self.param.S_max)\n",
        "\n",
        "        # Sample x\n",
        "        x_mean = (self.param.x_min + self.param.x_max) / 2\n",
        "        x_std = (self.param.x_max - self.param.x_min) / 6\n",
        "        x = torch.normal(x_mean, x_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        x = torch.clamp(x, min=self.param.x_min, max=self.param.x_max)\n",
        "\n",
        "        # Sample s ensuring |x - s| >= x_s_distance_min\n",
        "        s_mean = (self.param.s_min + self.param.s_max) / 2\n",
        "        s_std = (self.param.s_max - self.param.s_min) / 6\n",
        "        s = torch.normal(s_mean, s_std, size=(num_samples, 1), requires_grad=True).to(self.device)\n",
        "        s = torch.clamp(s, min=self.param.s_min, max=self.param.s_max)\n",
        "\n",
        "        # Enforce |x - s| >= x_s_distance_min\n",
        "        diff = torch.abs(x - s)\n",
        "        mask = diff < x_s_distance_min  # Find violations\n",
        "        while mask.any():\n",
        "            # Resample only the violated s values\n",
        "            resample_s = torch.normal(s_mean, s_std, size=(mask.sum(), 1), requires_grad=True).to(self.device)\n",
        "            resample_s = torch.clamp(resample_s, min=self.param.s_min, max=self.param.s_max)\n",
        "            s[mask] = resample_s.squeeze()\n",
        "            diff = torch.abs(x - s)\n",
        "            mask = diff < x_s_distance_min  # Recheck violations\n",
        "\n",
        "        # Return the concatenated tensor\n",
        "        return torch.cat([W, S, x, s], dim=1)\n",
        "\n",
        "\n",
        "    def sobolev_loss(self, outputs, y_target, X, sobolev_weight=1.0):\n",
        "        \"\"\"\n",
        "        Computes the Sobolev loss (already combined with relative error)\n",
        "\n",
        "        Parameters:\n",
        "            outputs: The model predictions of shape (B, 1).\n",
        "            y_target: The target values (initial guess) of shape (B, 1).\n",
        "            X: The input tensor of shape (B, 2)\n",
        "            sobolev_weight: The weighting factor for the derivative (Sobolev) term.\n",
        "\n",
        "        Returns:\n",
        "            Tensor:  Sobolev loss.\n",
        "        \"\"\"\n",
        "\n",
        "        value_loss = torch.mean(torch.square((outputs - y_target) / y_target))\n",
        "\n",
        "        grad_outputs = torch.ones_like(outputs)\n",
        "\n",
        "        grad_pred = torch.autograd.grad(\n",
        "            outputs, X, grad_outputs=grad_outputs,\n",
        "            create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        grad_target = torch.autograd.grad(\n",
        "            y_target, X, grad_outputs=grad_outputs,\n",
        "            create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        derivative_loss = torch.mean(torch.square(grad_pred - grad_target))\n",
        "\n",
        "        return value_loss + sobolev_weight * derivative_loss\n",
        "\n",
        "\n",
        "    def pretrain_y(self, epochs=1000, batch_size=1000, print_freq = 500):\n",
        "        \"\"\"\n",
        "        Pretrain the model using the initial guess.\n",
        "        \"\"\"\n",
        "        self.model_y.train(True)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            # Sample training data\n",
        "            X_pretrain = self.sample_data_y(batch_size)\n",
        "            x, s = X_pretrain[:, 0], X_pretrain[:, 1]\n",
        "\n",
        "            # Compute the initial guess\n",
        "            # y_pretrain = self.compute_initial_guess(W, S, x, s).view(-1, 1)\n",
        "            y_pretrain = self.compute_initial_guess_y(x, s).view(-1, 1)\n",
        "            # print(V_pretrain)\n",
        "\n",
        "            # Zero gradients\n",
        "            self.optimizer_y.zero_grad()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = self.model_y(X_pretrain)\n",
        "\n",
        "            loss = self.sobolev_loss(outputs, y_pretrain, X_pretrain)\n",
        "\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            self.pretrain_losses_y.append(loss.detach().item())\n",
        "            self.optimizer_y.step()\n",
        "\n",
        "            # Monitor training progress\n",
        "            if epoch % print_freq == 0 or epoch == 1:\n",
        "                print(f\"Pretrain Epoch {epoch}/{epochs}, Loss: {loss.item():.4e}\")\n",
        "\n",
        "            # Early stopping\n",
        "            if loss.item() < 1e-7:\n",
        "                print(f\"Pretraining for y converged at epoch {epoch} with loss {loss.item():.4e}\")\n",
        "                break\n",
        "\n",
        "    def pretrain_V(self, epochs=1000, batch_size=1000, print_freq = 500):\n",
        "        \"\"\"\n",
        "        Pretrain the model using the initial guess.\n",
        "        \"\"\"\n",
        "        self.model_V.train(True)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            # Sample training data\n",
        "            X_pretrain = self.sample_data_V(batch_size)\n",
        "            W, S, x, s = X_pretrain[:, 0], X_pretrain[:, 1], X_pretrain[:, 2], X_pretrain[:, 3]\n",
        "\n",
        "            # Compute the initial guess\n",
        "            # y_pretrain = self.compute_initial_guess(W, S, x, s).view(-1, 1)\n",
        "            V_pretrain = self.compute_initial_guess_V(W, S, x, s).view(-1, 1)\n",
        "            # print(V_pretrain)\n",
        "\n",
        "            # Zero gradients\n",
        "            self.optimizer_V.zero_grad()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = self.model_V(X_pretrain)\n",
        "\n",
        "            loss = self.sobolev_loss(outputs, V_pretrain, X_pretrain)\n",
        "\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            self.pretrain_losses_V.append(loss.detach().item())\n",
        "            self.optimizer_V.step()\n",
        "\n",
        "            # Monitor training progress\n",
        "            if epoch % print_freq == 0 or epoch == 1:\n",
        "                print(f\"Pretrain Epoch {epoch}/{epochs}, Loss: {loss.item():.4e}\")\n",
        "\n",
        "            # Early stopping\n",
        "            if loss.item() < 1e-7:\n",
        "                print(f\"Pretraining for V converged at epoch {epoch} with loss {loss.item():.4e}\")\n",
        "                break\n",
        "\n",
        "    class PDELoss(nn.Module):\n",
        "        def __init__(self, param, y, agg, x_grid, s_grid):\n",
        "            super().__init__()\n",
        "            self.param = param\n",
        "            self.y = torch.tensor(y, dtype=torch.float32, device = DEVICE)\n",
        "            self.agg = agg\n",
        "\n",
        "        def forward(self, model_y, model_V, inputs):\n",
        "            \"\"\"\n",
        "            inputs - (B, 4) tensor of (W, S, x, s)\n",
        "            \"\"\"\n",
        "\n",
        "            inputs_V = inputs\n",
        "            inputs_y = inputs[:, 2:]\n",
        "\n",
        "            # y and V\n",
        "            y = model_y(inputs_y).view(-1, )\n",
        "            V = model_V(inputs_V).view(-1, )\n",
        "\n",
        "            # derivatives for y and V\n",
        "            y_grad = torch.autograd.grad(y, inputs_y, grad_outputs=torch.ones_like(y),\n",
        "                                         create_graph=True, retain_graph=True)[0]\n",
        "            y_x = y_grad[:, 0]\n",
        "            y_s = y_grad[:, 1]\n",
        "            y_xx = torch.autograd.grad(y_x, inputs_y, grad_outputs=torch.ones_like(y_x),\n",
        "                                       create_graph=True, retain_graph=True)[0][:, 0]\n",
        "\n",
        "            V_grad = torch.autograd.grad(V, inputs_V, grad_outputs=torch.ones_like(V),\n",
        "                                         create_graph=True, retain_graph=True)[0]\n",
        "            V_W = V_grad[:, 0]\n",
        "            V_S = V_grad[:, 1]\n",
        "            V_x = V_grad[:, 2]\n",
        "            V_s = V_grad[:, 3]\n",
        "\n",
        "            V_WW = torch.autograd.grad(V_W, inputs_V, grad_outputs=torch.ones_like(V_W),\n",
        "                                    create_graph=True, retain_graph=True)[0][:, 0]\n",
        "            V_xx = torch.autograd.grad(V_x, inputs_V, grad_outputs=torch.ones_like(V_x),\n",
        "                                    create_graph=True, retain_graph=True)[0][:, 2]\n",
        "            V_Wx = torch.autograd.grad(V_W, inputs_V, grad_outputs=torch.ones_like(V_W),\n",
        "                                    create_graph=True, retain_graph=True)[0][:, 2]\n",
        "\n",
        "            W, S, x, s = inputs[:, 0], inputs[:, 1], inputs[:, 2], inputs[:, 3]\n",
        "\n",
        "            # Extract aggregates for y\n",
        "            r_X = self.agg.compute_r(x, s)\n",
        "            pi_X = self.agg.compute_pi(x, s)\n",
        "            mu_x = self.agg.compute_mu_x(x, s)\n",
        "            mu_s = self.agg.compute_mu_s(x, s)\n",
        "            sigma_x = self.agg.compute_sigma_x(x, s)\n",
        "            vd = self.agg.compute_vd(x, s)\n",
        "            sigma_R = self.agg.compute_sigma_R(x, s)\n",
        "            hat_r = r_X + self.param.gamma * self.param.sigma**2 - self.param.mu\n",
        "            hat_pi = pi_X - self.param.gamma * self.param.sigma * sigma_R\n",
        "\n",
        "            # Policy functions for V\n",
        "            Omega = torch.where(V_W != 0, V_S / V_W, torch.zeros_like(V_S))\n",
        "            n = (1 / self.param.chi) * ((1 - self.param.eta) / (2 - self.param.eta)) * Omega * y\n",
        "            theta = torch.where(Omega != 0,\n",
        "                                ((self.param.alpha_bar / vd) * torch.abs(Omega) / ((2 - self.param.eta) / y)) ** (1 / (1 - self.param.eta)),\n",
        "                                torch.zeros_like(Omega))\n",
        "\n",
        "            # Compute residual for y\n",
        "            y_term1 = r_X + pi_X\n",
        "            y_term2 = y + self.param.mu\n",
        "            y_term3 = (y_x * mu_x + y_s * mu_s) / y + 0.5 * y_xx * sigma_x ** 2 / y\n",
        "            y_term4 = (y_x * sigma_x / y) ** 2\n",
        "            y_term5 = self.param.sigma * y_x * sigma_x / y\n",
        "\n",
        "            y_residual = y_term1 - y_term2 + y_term3 - y_term4 + y_term5\n",
        "            y_residual_sq = (y_residual / y) ** 2\n",
        "\n",
        "            # Compute residual for V\n",
        "\n",
        "            V_term1 = self.param.rho_hat * V\n",
        "            # WARNING: I removed torch.abs(V_W), which we used so far\n",
        "            V_term2 = (self.param.gamma / (1 - self.param.gamma)) * (V_W ** ((self.param.gamma - 1) / self.param.gamma))\n",
        "            V_term3 = V_W * (hat_r * W + (hat_pi * S / y) + (vd * self.param.d_bar / y) -\n",
        "                           (theta * vd / y * torch.abs(n)) - (self.param.chi * n ** 2 / y * alpha_fn(theta, self.param)))\n",
        "            V_term4 = V_x * (mu_x + (1 - self.param.gamma) * self.param.sigma * sigma_x)\n",
        "            V_term5 = V_s * mu_s\n",
        "            V_term6 = V_S * n * alpha_fn(theta, self.param)\n",
        "            V_term7 = 0.5 * V_WW * (sigma_R * S / y - self.param.sigma * W) ** 2\n",
        "            V_term8 = 0.5 * V_xx * sigma_x ** 2\n",
        "            V_term9 = V_Wx * (sigma_R * S / y - self.param.sigma * W) * sigma_x\n",
        "\n",
        "            V_residual = V_term1 - V_term2 - (V_term3 + V_term4 + V_term5 + V_term6 + V_term7 + V_term8 + V_term9)\n",
        "            V_residual_sq = (V_residual / V) ** 2\n",
        "\n",
        "            # return torch.mean(y_residual_sq) + torch.mean(V_residual_sq)\n",
        "            return (V_residual_sq, y_residual_sq)\n",
        "\n",
        "\n",
        "    def train(self, num_samples=128, print_freq=100, loss_thres=1e-10, loss_equiv_const: float = 1e4):\n",
        "        \"\"\"\n",
        "        Train the model to solve the PDE after pretraining.\n",
        "\n",
        "        Parameters:\n",
        "            num_samples (int): Number of samples to generate for training at each epoch.\n",
        "            print_freq (int): Frequency at which to print the training loss.\n",
        "            loss_thres (float): The threshold value for stopping the training phase when the loss is smaller than this value.\n",
        "        \"\"\"\n",
        "        loss_fn = self.PDELoss(param = self.param, y = self.y, agg = self.agg,\n",
        "                               x_grid = self.x_grid, s_grid = self.s_grid)\n",
        "\n",
        "        for phase_indx, phase in enumerate(self.phases):\n",
        "            self.param.sigma = phase.sigma\n",
        "            self.optimizer = optim.Adam(chain(self.model_V.parameters(),\n",
        "                                              self.model_y.parameters()),\n",
        "                                        lr=phase.lr)\n",
        "            self.update_training_mode(phase.mode)\n",
        "\n",
        "            for epoch in range(1, phase.epochs + 1):\n",
        "                # Sample data points\n",
        "                data = self.sample_data_V(num_samples).to(self.device)\n",
        "\n",
        "                # Zero gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Compute loss\n",
        "                (V_residual_sq, y_residual_sq) = loss_fn(model_y = self.model_y,\n",
        "                                                         model_V = self.model_V,\n",
        "                                                         inputs = data)\n",
        "                loss_V = torch.mean(V_residual_sq)\n",
        "                loss_y = torch.mean(y_residual_sq)\n",
        "                # loss = loss_V + loss_equiv_const * loss_y\n",
        "                loss = loss_V + loss_y\n",
        "\n",
        "                print(loss)\n",
        "\n",
        "                if torch.isnan(loss):\n",
        "                    print(f\"Warning: NaN detected in loss at Phase {phase_indx}, Epoch {epoch}. Skipping update.\")\n",
        "\n",
        "                    torch.save(data, f\"problematic_input_phase{phase_indx}_epoch{epoch}.pt\")\n",
        "                    continue\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.agg.flush_cache()\n",
        "                self.train_losses.append([loss_V.detach().item(), loss_y.detach().item()])\n",
        "\n",
        "                # Monitor training progress\n",
        "                if epoch % print_freq == 0 or epoch == 1:\n",
        "                    print(f\"Phase {phase_indx}, Epoch {epoch}/{phase.epochs}, Loss: {loss.item():.4e}\")\n",
        "                    # self.visualize_inputs(save_path=fig_path, phase = phase, epoch=epoch)\n",
        "\n",
        "                # Check if the loss is below the threshold and stop the phase if it is\n",
        "                if loss.item() < loss_thres:\n",
        "                    print(f\"Phase {phase_indx} stopped early at Epoch {epoch} due to loss threshold {loss_thres}.\")\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1886e597-c2b4-4141-b36b-a3e3261e6954",
      "metadata": {
        "id": "1886e597-c2b4-4141-b36b-a3e3261e6954"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Initialize the Train_NN instance\n",
        "train_nn = Train_NN(param, input_dim=2, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v0hRY57-nduq",
      "metadata": {
        "id": "v0hRY57-nduq"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Check whether to pretrain or load the existing model\n",
        "if loading_saved_model == False:\n",
        "    print(\"Starting pretraining...\")\n",
        "    train_nn.pretrain_V(epochs=1_000, batch_size=1024)\n",
        "    train_nn.pretrain_y(epochs=1_000, batch_size=1024)\n",
        "\n",
        "    # Save the pretrained model\n",
        "    torch.save({\n",
        "        'model_state_dict': train_nn.model_V.state_dict(),\n",
        "        'optimizer_state_dict': train_nn.optimizer_V.state_dict(),\n",
        "    }, model_load_path)\n",
        "    print(f\"Pretrained model for V saved at {model_load_path}\")\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': train_nn.model_y.state_dict(),\n",
        "        'optimizer_state_dict': train_nn.optimizer_y.state_dict(),\n",
        "    }, model_load_path)\n",
        "    print(f\"Pretrained model for y saved at {model_load_path}\")\n",
        "\n",
        "    # Plot and save the pretraining loss\n",
        "    plt.figure()\n",
        "    plt.plot(train_nn.pretrain_losses_y)\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss during pretrain')\n",
        "    plt.title('Pretraining Loss for y')\n",
        "    plt.savefig(f\"{fig_path}/pretrain_loss.png\")  # Save the plot\n",
        "    # plt.close()\n",
        "    print(f\"Pretraining loss plot saved at {fig_path}/pretrain_loss_y.png\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_nn.pretrain_losses_V)\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss during pretrain')\n",
        "    plt.title('Pretraining Loss for V')\n",
        "    plt.savefig(f\"{fig_path}/pretrain_loss.png\")  # Save the plot\n",
        "    # plt.close()\n",
        "    print(f\"Pretraining loss plot saved at {fig_path}/pretrain_loss_V.png\")\n",
        "\n",
        "else:\n",
        "    # Load the pretrained model\n",
        "    checkpoint = torch.load(model_load_path, map_location=train_nn.device)\n",
        "    train_nn.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    train_nn.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(f\"Model loaded from {model_load_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fdeab71",
      "metadata": {
        "id": "7fdeab71"
      },
      "outputs": [],
      "source": [
        "# # Load the pretrained model\n",
        "# checkpoint = torch.load(model_save_path, map_location=train_nn.device)\n",
        "# train_nn.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# train_nn.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# print(f\"Model loaded from {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14a08fd-2943-4e7e-9b6f-9b6c0e691ee6",
      "metadata": {
        "id": "e14a08fd-2943-4e7e-9b6f-9b6c0e691ee6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# After pretraining, proceed with training\n",
        "train_nn.train(num_samples=1024, print_freq=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ph5y070BuLen",
      "metadata": {
        "id": "ph5y070BuLen"
      },
      "outputs": [],
      "source": [
        "# Save the trained model and optimizer state\n",
        "# TODO: not rewritten for a combined trainer\n",
        "torch.save({\n",
        "    'model_state_dict': train_nn.model_V.state_dict(),\n",
        "    'optimizer_state_dict': train_nn.optimizer.state_dict(),\n",
        "    'training_losses': train_nn.train_losses,\n",
        "}, model_V_save_path)\n",
        "print(f\"Training solution saved to {model_V_save_path}\")\n",
        "torch.save({\n",
        "    'model_state_dict': train_nn.model_y.state_dict(),\n",
        "    'optimizer_state_dict': train_nn.optimizer.state_dict(),\n",
        "    'training_losses': train_nn.train_losses,\n",
        "}, model_y_save_path)\n",
        "print(f\"Training solution saved to {model_y_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TjIp1wRjRYZd",
      "metadata": {
        "collapsed": true,
        "id": "TjIp1wRjRYZd"
      },
      "outputs": [],
      "source": [
        "len(train_nn.train_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cgn6nyIXRLCP",
      "metadata": {
        "id": "cgn6nyIXRLCP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "loss_V = [loss[0] for loss in train_nn.train_losses]\n",
        "loss_y = [loss[1] for loss in train_nn.train_losses]\n",
        "plt.plot(loss_V, label='Loss_V')\n",
        "plt.plot(loss_y, label='Loss_y')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epoch', fontsize=20)\n",
        "plt.ylabel('Training Loss', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.legend()\n",
        "plt.savefig(fig_path + f\"/train_loss.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lrcf0-ycD0oy",
      "metadata": {
        "id": "lrcf0-ycD0oy"
      },
      "outputs": [],
      "source": [
        "# Define fixed values for W, S, x, s\n",
        "x_value = 0.9   # Fixed x\n",
        "s_value = 0.5   # Varying s\n",
        "\n",
        "# Generate s values for the plot\n",
        "s_values = torch.linspace(param.s_min, param.s_max, 500).unsqueeze(1).to(train_nn.device)\n",
        "\n",
        "# Prepare inputs for the neural network\n",
        "# W_tensor = torch.full_like(s_values, W_value)\n",
        "x_tensor = torch.full_like(s_values, x_value)\n",
        "s_tensor = s_values\n",
        "inputs = torch.cat([x_tensor, s_tensor], dim=1)\n",
        "\n",
        "# Get the outputs from the neural network (y(x, s))\n",
        "nn_outputs = train_nn.model_y(inputs).detach().cpu().numpy()\n",
        "\n",
        "# Compute the initial guess for y(x, s)\n",
        "initial_guess = train_nn.compute_initial_guess_y(\n",
        "    x=x_tensor,\n",
        "    s=s_tensor\n",
        ").cpu().numpy()\n",
        "\n",
        "# Plot both the neural network outputs and the initial guess\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(s_values.cpu().numpy(), nn_outputs, label=\"NN Solution\", linewidth=2)\n",
        "plt.plot(s_values.cpu().numpy(), initial_guess, label=\"Initial Guess\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"s\", fontsize=20)\n",
        "plt.ylabel(\"y(s)\", fontsize=20)\n",
        "plt.title(f\"NN Solution of y(x,s) vs Initial Guess at x={x_value}\", fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig(f\"{fig_path}/comparison_y_x_{x_value}.png\", bbox_inches=\"tight\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e0bf6d",
      "metadata": {
        "id": "d6e0bf6d"
      },
      "outputs": [],
      "source": [
        "# Define fixed values for W, S, x, s\n",
        "x_value = 0.1   # Fixed x\n",
        "s_value = 0.5   # Varying s\n",
        "\n",
        "# Generate s values for the plot\n",
        "s_values = torch.linspace(param.s_min, param.s_max, 500).unsqueeze(1).to(train_nn.device)\n",
        "\n",
        "# Prepare inputs for the neural network\n",
        "# W_tensor = torch.full_like(s_values, W_value)\n",
        "x_tensor = torch.full_like(s_values, x_value)\n",
        "s_tensor = s_values\n",
        "inputs = torch.cat([x_tensor, s_tensor], dim=1)\n",
        "\n",
        "# Get the outputs from the neural network (y(x, s))\n",
        "nn_outputs = train_nn.model_y(inputs).detach().cpu().numpy()\n",
        "\n",
        "# Compute the initial guess for y(x, s)\n",
        "initial_guess = train_nn.compute_initial_guess_y(\n",
        "    x=x_tensor,\n",
        "    s=s_tensor\n",
        ").cpu().numpy()\n",
        "\n",
        "# Plot both the neural network outputs and the initial guess\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(s_values.cpu().numpy(), nn_outputs, label=\"NN Solution\", linewidth=2)\n",
        "plt.plot(s_values.cpu().numpy(), initial_guess, label=\"Initial Guess\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"s\", fontsize=20)\n",
        "plt.ylabel(\"y(s)\", fontsize=20)\n",
        "plt.title(f\"NN Solution of y(x,s) vs Initial Guess at x={x_value}\", fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig(f\"{fig_path}/comparison_y_x_{x_value}.png\", bbox_inches=\"tight\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cp2QsJyKgc3q",
      "metadata": {
        "id": "Cp2QsJyKgc3q"
      },
      "outputs": [],
      "source": [
        "# Define fixed values for W, S, x, s\n",
        "x_value = 0.5   # Fixed x\n",
        "s_value = 0.5   # Varying s\n",
        "\n",
        "# Generate s values for the plot\n",
        "s_values = torch.linspace(param.s_min, param.s_max, 500).unsqueeze(1).to(train_nn.device)\n",
        "\n",
        "# Prepare inputs for the neural network\n",
        "# W_tensor = torch.full_like(s_values, W_value)\n",
        "x_tensor = torch.full_like(s_values, x_value)\n",
        "s_tensor = s_values\n",
        "inputs = torch.cat([x_tensor, s_tensor], dim=1)\n",
        "\n",
        "# Get the outputs from the neural network (y(x, s))\n",
        "nn_outputs = train_nn.model_y(inputs).detach().cpu().numpy()\n",
        "\n",
        "# Compute the initial guess for y(x, s)\n",
        "initial_guess = train_nn.compute_initial_guess_y(\n",
        "    x=x_tensor,\n",
        "    s=s_tensor\n",
        ").cpu().numpy()\n",
        "\n",
        "# Plot both the neural network outputs and the initial guess\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(s_values.cpu().numpy(), nn_outputs, label=\"NN Solution\", linewidth=2)\n",
        "plt.plot(s_values.cpu().numpy(), initial_guess, label=\"Initial Guess\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"s\", fontsize=20)\n",
        "plt.ylabel(\"y(s)\", fontsize=20)\n",
        "plt.title(f\"NN Solution of y(x,s) vs Initial Guess at x={x_value}\", fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig(f\"{fig_path}/comparison_y_x_{x_value}.png\", bbox_inches=\"tight\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xXTOYPAWuA5u",
      "metadata": {
        "id": "xXTOYPAWuA5u"
      },
      "outputs": [],
      "source": [
        "# Define fixed values for S, x, s\n",
        "S_value = 1.0  # Fixed S\n",
        "x_value = 0.5  # Fixed x\n",
        "s_value = 0.5  # Fixed s\n",
        "\n",
        "# Generate W values for the plot\n",
        "W_values = torch.linspace(10, 50, 500).unsqueeze(1).to(train_nn.device)\n",
        "\n",
        "# Prepare inputs for the neural network\n",
        "S_tensor = torch.full_like(W_values, S_value)\n",
        "x_tensor = torch.full_like(W_values, x_value)\n",
        "s_tensor = torch.full_like(W_values, s_value)\n",
        "inputs = torch.cat([W_values, S_tensor, x_tensor, s_tensor], dim=1)\n",
        "\n",
        "# Get the outputs from the neural network\n",
        "nn_outputs = train_nn.model_V(inputs).detach().cpu().numpy()\n",
        "\n",
        "# Compute the initial guess\n",
        "initial_guess = train_nn.compute_initial_guess_V(\n",
        "    W=W_values,\n",
        "    S=S_tensor,\n",
        "    x=x_tensor,\n",
        "    s=s_tensor\n",
        ").cpu().numpy()\n",
        "\n",
        "# Plot both the neural network outputs and the initial guess\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(W_values.cpu().numpy(), nn_outputs, label=\"NN Solution\", linewidth=2)\n",
        "plt.plot(W_values.cpu().numpy(), initial_guess, label=\"Initial Guess\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"W\", fontsize=20)\n",
        "plt.ylabel(\"V(W)\", fontsize=20)\n",
        "plt.title(f\"NN Solution vs Initial Guess at S={S_value}, x={x_value}, s={s_value}\", fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "# Save the plot\n",
        "fig_path = \"./fig\"  # Adjust the path as needed\n",
        "plt.savefig(f\"{fig_path}/comparison.png\", bbox_inches=\"tight\")\n",
        "# plt.close()\n",
        "\n",
        "plt.savefig(fig_path + f\"/comparison_V_W_S_{S_value}_x_{x_value}_s_{s_value}_0505.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g8uzz7rdUxUf",
      "metadata": {
        "id": "g8uzz7rdUxUf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example s-values\n",
        "s_vals = [0.25, 0.5, 0.75]\n",
        "\n",
        "# Set up a figure with 1 row and 2 columns of subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "# Optional: define colors/linestyles to differentiate s-values\n",
        "colors = ['blue', 'red', 'green']\n",
        "linestyles = ['--', '-', ':']\n",
        "pi_repr = train_nn.agg.compute_pi(torch.tensor(0.5, requires_grad=True, device = train_nn.device),\n",
        "                         torch.tensor(0.5, requires_grad=True, device = train_nn.device)).item()\n",
        "train_nn.agg.flush_cache()\n",
        "\n",
        "\n",
        "# Left subplot: Risk Premium\n",
        "for i, s in enumerate(s_vals):\n",
        "    x = torch.linspace(0.25, 0.75, 100, requires_grad=True, device = train_nn.device)\n",
        "    s_tensor = torch.full((100,), s, requires_grad=True, device = train_nn.device)\n",
        "\n",
        "    # Call your function that computes the risk premium pi(x, s)\n",
        "    pi_vals = train_nn.agg.compute_pi(x, s_tensor) / pi_repr\n",
        "    train_nn.agg.flush_cache()\n",
        "    axes[0].plot(\n",
        "        x.detach().cpu().numpy(),\n",
        "        pi_vals.detach().cpu().numpy(),\n",
        "        label=fr\"$s={s}$\",\n",
        "        color=colors[i],\n",
        "        linestyle=linestyles[i],\n",
        "        linewidth=2\n",
        "    )\n",
        "\n",
        "axes[0].set_title(\"Risk Premium\", fontsize=14)\n",
        "axes[0].set_xlabel(\"Wealth share $x$\", fontsize=12)\n",
        "axes[0].set_ylabel(r\"$\\pi/\\pi_{repr}$\", fontsize=12)\n",
        "axes[0].grid(True)\n",
        "axes[0].legend(fontsize=10)\n",
        "\n",
        "# Right subplot: Interest Rate\n",
        "for i, s in enumerate(s_vals):\n",
        "    x = torch.linspace(0.25, 0.75, 100, requires_grad=True, device = train_nn.device)\n",
        "    s_tensor = torch.full((100,), s, requires_grad=True, device = train_nn.device)\n",
        "\n",
        "    # Call your function that computes the interest rate r(x, s)\n",
        "    r_vals = train_nn.agg.compute_r(x, s_tensor)\n",
        "    train_nn.agg.flush_cache()\n",
        "\n",
        "    axes[1].plot(\n",
        "        x.detach().cpu().numpy(),\n",
        "        r_vals.detach().cpu().numpy(),\n",
        "        label=fr\"$s={s}$\",\n",
        "        color=colors[i],\n",
        "        linestyle=linestyles[i],\n",
        "        linewidth=2\n",
        "    )\n",
        "\n",
        "axes[1].set_title(\"Interest Rate\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Wealth share $x$\", fontsize=12)\n",
        "axes[1].set_ylabel(r\"$r(x,s)$\", fontsize=12)\n",
        "axes[1].grid(True)\n",
        "axes[1].legend(fontsize=10)\n",
        "\n",
        "# Adjust spacing and show\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"r,pi_plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nSbl2DYAZeLE",
      "metadata": {
        "id": "nSbl2DYAZeLE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}